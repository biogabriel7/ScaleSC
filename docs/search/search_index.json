{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ScaleSC ScaleSC A GPU-accelerated tool for large scale scRNA-seq pipeline. Highlights \u2022 Why ScaleSC \u2022 Installation \u2022 API Reference Highlights Fast scRNA-seq pipeline including QC, Normalization, Batch-effect Removal, Dimension Reduction in a similar syntax as scanpy and rapids-singlecell . Scale to dataset with more than 10M cells. Chunk the data to avoid the int32 limitation in cupyx.scipy.sparse used by rapids-singlecell that disables the computing for even moderate-size dataset (~1M). Reconcile output at each step to scanpy to reproduce the same results as on CPU end. Improvement on harmonypy which allows dataset with more than 10M cells and more than 1000 samples to be run on a single GPU (A100 80G). Why ScaleSC ScaleSC Pipeline ScaleSC includes regular prerpocessing steps: QC, Filtering, HVG, PCA, Batch Correction, Clustering, Annotation. Overview of 3 different packages* scanpy scalesc rapids-singlecell GPU Support \u274c \u2705 \u2705 int32 Issue \u274c \u274c \u2705 Upper Limit of # Cells \u267e\ufe0f ~20M ~1M Upper Limit of # Samples \u267e\ufe0f >1000 < 100 * Test on datasets with ~35k genes. ScaleSC only support to run Harmony on a single GPU, this memory limitation greatly limits the capability of scaling to even larger dataset. However, there would be no limitation on number of cells if you prefer not to run Harmony (QC, HVG, and PCA only). Time comparsion between Scanpy(CPU) and ScaleSC(GPU) on A100(80G) ScaleSC significantly reduces running time from hours to several minutes. For the extremely large 13M dataset, ScaleSC can finish all steps in just 1 hour! How To Install Note: ScaleSC requires a high-end GPU (> 24G VRAM) and a matching CUDA version to support GPU-accelerated computing. Requirements : RAPIDS from Nvidia rapids-singlecell , an alternative of scanpy that employs GPU for acceleration. Conda , version >=22.11 is strongly encoruaged, because conda-libmamba-solver is set as default, which significant speeds up solving dependencies. pip , a python package installer. Environment Setup : Install RAPIDS through Conda, conda create -n scalesc -c rapidsai -c conda-forge -c nvidia rapids=24.10 python=3.10 'cuda-version>=11.4,<=11.8' Users have flexibility to install it according to their systems by using this online selector . Activate conda env, conda activate scalesc Install rapids-singlecell using pip, pip install rapids-singlecell Install scaleSC, pull scaleSC from github git clone https://github.com/interactivereport/scaleSC.git enter the folder and install scaleSC cd scaleSC pip install . check env: python -c \"import scalesc; print(scalesc.__version__)\" == 0.1.0 python -c \"import cupy; print(cupy.__version__)\" >= 13.3.0 python -c \"import cuml; print(cuml.__version__)\" >= 24.10 python -c \"import cupy; print(cupy.cuda.is_available())\" = True python -c \"import xgboost; print(xgboost.__version__) >= 2.1.1, optionally for marker annotation Tutorial See this tutorial for details.","title":"Get Started"},{"location":"#welcome-to-scalesc","text":"","title":"Welcome to ScaleSC"},{"location":"#highlights","text":"Fast scRNA-seq pipeline including QC, Normalization, Batch-effect Removal, Dimension Reduction in a similar syntax as scanpy and rapids-singlecell . Scale to dataset with more than 10M cells. Chunk the data to avoid the int32 limitation in cupyx.scipy.sparse used by rapids-singlecell that disables the computing for even moderate-size dataset (~1M). Reconcile output at each step to scanpy to reproduce the same results as on CPU end. Improvement on harmonypy which allows dataset with more than 10M cells and more than 1000 samples to be run on a single GPU (A100 80G).","title":"Highlights"},{"location":"#why-scalesc","text":"ScaleSC Pipeline ScaleSC includes regular prerpocessing steps: QC, Filtering, HVG, PCA, Batch Correction, Clustering, Annotation. Overview of 3 different packages* scanpy scalesc rapids-singlecell GPU Support \u274c \u2705 \u2705 int32 Issue \u274c \u274c \u2705 Upper Limit of # Cells \u267e\ufe0f ~20M ~1M Upper Limit of # Samples \u267e\ufe0f >1000 < 100 * Test on datasets with ~35k genes. ScaleSC only support to run Harmony on a single GPU, this memory limitation greatly limits the capability of scaling to even larger dataset. However, there would be no limitation on number of cells if you prefer not to run Harmony (QC, HVG, and PCA only). Time comparsion between Scanpy(CPU) and ScaleSC(GPU) on A100(80G) ScaleSC significantly reduces running time from hours to several minutes. For the extremely large 13M dataset, ScaleSC can finish all steps in just 1 hour!","title":"Why ScaleSC"},{"location":"#how-to-install","text":"Note: ScaleSC requires a high-end GPU (> 24G VRAM) and a matching CUDA version to support GPU-accelerated computing. Requirements : RAPIDS from Nvidia rapids-singlecell , an alternative of scanpy that employs GPU for acceleration. Conda , version >=22.11 is strongly encoruaged, because conda-libmamba-solver is set as default, which significant speeds up solving dependencies. pip , a python package installer. Environment Setup : Install RAPIDS through Conda, conda create -n scalesc -c rapidsai -c conda-forge -c nvidia rapids=24.10 python=3.10 'cuda-version>=11.4,<=11.8' Users have flexibility to install it according to their systems by using this online selector . Activate conda env, conda activate scalesc Install rapids-singlecell using pip, pip install rapids-singlecell Install scaleSC, pull scaleSC from github git clone https://github.com/interactivereport/scaleSC.git enter the folder and install scaleSC cd scaleSC pip install . check env: python -c \"import scalesc; print(scalesc.__version__)\" == 0.1.0 python -c \"import cupy; print(cupy.__version__)\" >= 13.3.0 python -c \"import cuml; print(cuml.__version__)\" >= 24.10 python -c \"import cupy; print(cupy.cuda.is_available())\" = True python -c \"import xgboost; print(xgboost.__version__) >= 2.1.1, optionally for marker annotation","title":"How To Install"},{"location":"#tutorial","text":"See this tutorial for details.","title":"Tutorial"},{"location":"api-docs/","text":"API Reference Modules harmonypy_gpu kernels pp trim_merge_marker util Classes harmonypy_gpu.Harmony pp.ScaleSC : ScaleSC integrated pipeline in a scanpy-like style. trim_merge_marker.UF trim_merge_marker.data2UF util.AnnDataBatchReader : Chunked dataloader for extremely large single-cell dataset. Return a data chunk each time for further processing. Functions harmonypy_gpu.get_dummies : Return a sparse dummy matrix. harmonypy_gpu.get_usage harmonypy_gpu.moe_correct_ridge harmonypy_gpu.run_harmony : Run Harmony. harmonypy_gpu.safe_entropy harmonypy_gpu.to_csc_cuda : Move to GPU as a csc_matrix, speed up column slice. harmonypy_gpu.to_csr_cuda : Move to GPU as a csr_matrix. kernels.get_find_indices kernels.get_mean_var_major kernels.get_mean_var_minor trim_merge_marker.X_to_GPU : Transfers matrices and arrays to the GPU. trim_merge_marker.adata_cluster_merge : Need a description. trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.find_cluster_pairs_to_merge trim_merge_marker.find_markers trim_merge_marker.fraction_cells : Given adata.X (n cells * m genes), ctype_col (a column name in adata.obs that stores the cell type annotation), and a glist (for example, [gene1, gene2, ..., genek]) trim_merge_marker.marker_filter_sort trim_merge_marker.wrapper trim_merge_marker.myNSForest trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.specificity_score trim_merge_marker.stds : Variance of sparse matrix a trim_merge_marker.timer util.check_dtype : Convert dtype to float32 or float64 . util.check_nonnegative_integers : Check if X is a nonnegative integer matrix. util.correct_leiden util.csr_col_index util.csr_indptr_to_coo_rows util.csr_row_index : Populate indices and data arrays from the given row index. util.filter_cells : Cell filtering according to min and max gene counts. util.find_indices util.gc : Release CPU and GPU RAM util.get_mean_var : Calculating mean and variance of a given matrix based on customized kernels. util.harmony : Harmony GPU version. util.svd_flip : Flip the signs of loading according to sign(max(abs(loadings))). util.write_to_disk This file was automatically generated via lazydocs .","title":"Overview"},{"location":"api-docs/#api-reference","text":"","title":"API Reference"},{"location":"api-docs/#modules","text":"harmonypy_gpu kernels pp trim_merge_marker util","title":"Modules"},{"location":"api-docs/#classes","text":"harmonypy_gpu.Harmony pp.ScaleSC : ScaleSC integrated pipeline in a scanpy-like style. trim_merge_marker.UF trim_merge_marker.data2UF util.AnnDataBatchReader : Chunked dataloader for extremely large single-cell dataset. Return a data chunk each time for further processing.","title":"Classes"},{"location":"api-docs/#functions","text":"harmonypy_gpu.get_dummies : Return a sparse dummy matrix. harmonypy_gpu.get_usage harmonypy_gpu.moe_correct_ridge harmonypy_gpu.run_harmony : Run Harmony. harmonypy_gpu.safe_entropy harmonypy_gpu.to_csc_cuda : Move to GPU as a csc_matrix, speed up column slice. harmonypy_gpu.to_csr_cuda : Move to GPU as a csr_matrix. kernels.get_find_indices kernels.get_mean_var_major kernels.get_mean_var_minor trim_merge_marker.X_to_GPU : Transfers matrices and arrays to the GPU. trim_merge_marker.adata_cluster_merge : Need a description. trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.find_cluster_pairs_to_merge trim_merge_marker.find_markers trim_merge_marker.fraction_cells : Given adata.X (n cells * m genes), ctype_col (a column name in adata.obs that stores the cell type annotation), and a glist (for example, [gene1, gene2, ..., genek]) trim_merge_marker.marker_filter_sort trim_merge_marker.wrapper trim_merge_marker.myNSForest trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.wrapper trim_merge_marker.specificity_score trim_merge_marker.stds : Variance of sparse matrix a trim_merge_marker.timer util.check_dtype : Convert dtype to float32 or float64 . util.check_nonnegative_integers : Check if X is a nonnegative integer matrix. util.correct_leiden util.csr_col_index util.csr_indptr_to_coo_rows util.csr_row_index : Populate indices and data arrays from the given row index. util.filter_cells : Cell filtering according to min and max gene counts. util.find_indices util.gc : Release CPU and GPU RAM util.get_mean_var : Calculating mean and variance of a given matrix based on customized kernels. util.harmony : Harmony GPU version. util.svd_flip : Flip the signs of loading according to sign(max(abs(loadings))). util.write_to_disk This file was automatically generated via lazydocs .","title":"Functions"},{"location":"api-docs/harmonypy_gpu/","text":"module harmonypy_gpu function get_usage get_usage(s) function to_csr_cuda to_csr_cuda(x, dtype) Move to GPU as a csr_matrix. function to_csc_cuda to_csc_cuda(x, dtype) Move to GPU as a csc_matrix, speed up column slice. function get_dummies get_dummies(x) Return a sparse dummy matrix. function run_harmony run_harmony( data_mat: 'ndarray', meta_data: 'DataFrame', vars_use, init_seeds=None, theta=None, lamb=None, sigma=0.1, nclust=None, tau=0, block_size=0.05, max_iter_harmony=10, max_iter_kmeans=20, epsilon_cluster=1e-05, epsilon_harmony=0.0001, plot_convergence=False, verbose=True, reference_values=None, cluster_prior=None, n_init=1, random_state=0, dtype=<class 'numpy.float32'> ) Run Harmony. function safe_entropy safe_entropy(x: 'array') function moe_correct_ridge moe_correct_ridge(Z_orig, Z_cos, Z_corr, R, W, K, Phi_Rk, Phi_moe, lamb) class Harmony method __init__ __init__( Z, init_seeds, n_init, Phi, Phi_moe, Pr_b, sigma, theta, max_iter_harmony, max_iter_kmeans, epsilon_kmeans, epsilon_harmony, K, block_size, lamb, verbose, random_state, dtype ) method allocate_buffers allocate_buffers() method check_convergence check_convergence(i_type) method cluster cluster() method compute_objective compute_objective() method harmonize harmonize(iter_harmony=10, verbose=True) method init_cluster init_cluster() method kmeans_multirestart kmeans_multirestart() method result result() method update_R update_R() This file was automatically generated via lazydocs .","title":"Harmonypy gpu"},{"location":"api-docs/harmonypy_gpu/#module-harmonypy_gpu","text":"","title":"module harmonypy_gpu"},{"location":"api-docs/harmonypy_gpu/#function-get_usage","text":"get_usage(s)","title":"function get_usage"},{"location":"api-docs/harmonypy_gpu/#function-to_csr_cuda","text":"to_csr_cuda(x, dtype) Move to GPU as a csr_matrix.","title":"function to_csr_cuda"},{"location":"api-docs/harmonypy_gpu/#function-to_csc_cuda","text":"to_csc_cuda(x, dtype) Move to GPU as a csc_matrix, speed up column slice.","title":"function to_csc_cuda"},{"location":"api-docs/harmonypy_gpu/#function-get_dummies","text":"get_dummies(x) Return a sparse dummy matrix.","title":"function get_dummies"},{"location":"api-docs/harmonypy_gpu/#function-run_harmony","text":"run_harmony( data_mat: 'ndarray', meta_data: 'DataFrame', vars_use, init_seeds=None, theta=None, lamb=None, sigma=0.1, nclust=None, tau=0, block_size=0.05, max_iter_harmony=10, max_iter_kmeans=20, epsilon_cluster=1e-05, epsilon_harmony=0.0001, plot_convergence=False, verbose=True, reference_values=None, cluster_prior=None, n_init=1, random_state=0, dtype=<class 'numpy.float32'> ) Run Harmony.","title":"function run_harmony"},{"location":"api-docs/harmonypy_gpu/#function-safe_entropy","text":"safe_entropy(x: 'array')","title":"function safe_entropy"},{"location":"api-docs/harmonypy_gpu/#function-moe_correct_ridge","text":"moe_correct_ridge(Z_orig, Z_cos, Z_corr, R, W, K, Phi_Rk, Phi_moe, lamb)","title":"function moe_correct_ridge"},{"location":"api-docs/harmonypy_gpu/#class-harmony","text":"","title":"class Harmony"},{"location":"api-docs/harmonypy_gpu/#method-__init__","text":"__init__( Z, init_seeds, n_init, Phi, Phi_moe, Pr_b, sigma, theta, max_iter_harmony, max_iter_kmeans, epsilon_kmeans, epsilon_harmony, K, block_size, lamb, verbose, random_state, dtype )","title":"method __init__"},{"location":"api-docs/harmonypy_gpu/#method-allocate_buffers","text":"allocate_buffers()","title":"method allocate_buffers"},{"location":"api-docs/harmonypy_gpu/#method-check_convergence","text":"check_convergence(i_type)","title":"method check_convergence"},{"location":"api-docs/harmonypy_gpu/#method-cluster","text":"cluster()","title":"method cluster"},{"location":"api-docs/harmonypy_gpu/#method-compute_objective","text":"compute_objective()","title":"method compute_objective"},{"location":"api-docs/harmonypy_gpu/#method-harmonize","text":"harmonize(iter_harmony=10, verbose=True)","title":"method harmonize"},{"location":"api-docs/harmonypy_gpu/#method-init_cluster","text":"init_cluster()","title":"method init_cluster"},{"location":"api-docs/harmonypy_gpu/#method-kmeans_multirestart","text":"kmeans_multirestart()","title":"method kmeans_multirestart"},{"location":"api-docs/harmonypy_gpu/#method-result","text":"result()","title":"method result"},{"location":"api-docs/harmonypy_gpu/#method-update_r","text":"update_R() This file was automatically generated via lazydocs .","title":"method update_R"},{"location":"api-docs/kernels/","text":"module kernels Global Variables get_mean_var_major_kernel get_mean_var_minor_kernel find_indices_kernel function get_mean_var_major get_mean_var_major(dtype) function get_mean_var_minor get_mean_var_minor(dtype) function get_find_indices get_find_indices() This file was automatically generated via lazydocs .","title":"scalesc.kernels"},{"location":"api-docs/kernels/#module-kernels","text":"","title":"module kernels"},{"location":"api-docs/kernels/#global-variables","text":"get_mean_var_major_kernel get_mean_var_minor_kernel find_indices_kernel","title":"Global Variables"},{"location":"api-docs/kernels/#function-get_mean_var_major","text":"get_mean_var_major(dtype)","title":"function get_mean_var_major"},{"location":"api-docs/kernels/#function-get_mean_var_minor","text":"get_mean_var_minor(dtype)","title":"function get_mean_var_minor"},{"location":"api-docs/kernels/#function-get_find_indices","text":"get_find_indices() This file was automatically generated via lazydocs .","title":"function get_find_indices"},{"location":"api-docs/pp/","text":"module pp Global Variables get_mean_var_major_kernel get_mean_var_minor_kernel find_indices_kernel class ScaleSC ScaleSC integrated pipeline in a scanpy-like style. It will automatcially load dataset in chunks, see scalesc.util.AnnDataBatchReader for details, and all methods in this class manipulate this chunked data. Args: data_dir ( str ): Data folder of the dataset. max_cell_batch ( int ): Maximum number of cells in a single batch. Default : 100000. preload_on_cpu ( bool ): If load the entire chunked data on CPU. Default: True preload_on_gpu ( bool ): If load the entire chunked data on GPU, preload_on_cpu will be overwritten to True when this sets to True . Default : True . save_raw_counts ( bool ): If save adata_X to disk after QC filtering. Default : False. save_norm_counts ( bool ): If save adata_X data to disk after normalization. Default : False. save_after_each_step ( bool ): If save adata (without .X) to disk after each step. Default : False. output_dir ( str ): Output folder. Default: './results'. gpus ( list ): List of GPU ids, [0] is set if this is None. Default: None. method __init__ __init__( data_dir, max_cell_batch=100000.0, preload_on_cpu=True, preload_on_gpu=True, save_raw_counts=False, save_norm_counts=False, save_after_each_step=False, output_dir='results', gpus=None ) property adata AnnData : An AnnData object that used to store all intermediate results without the count matrix. Note: This is always on CPU. property adata_X AnnData : An AnnData object that used to store all intermediate results including the count matrix. Internally, all chunks should be merged on CPU to avoid high GPU consumption, make sure to invoke to_CPU() before calling this object. method calculate_qc_metrics calculate_qc_metrics() Calculate quality control metrics. method clear clear() Clean the memory method filter_cells filter_cells(min_count=0, max_count=None, qc_var='n_genes_by_counts', qc=False) Filter genes based on number of a QC metric. Args: min_count ( int ): Minimum number of counts required for a cell to pass filtering. max_count ( int ): Maximum number of counts required for a cell to pass filtering. qc_var ( str ='n_genes_by_counts'): Feature in QC metrics that used to filter cells. qc ( bool = False ): Call calculate_qc_metrics before filtering. method filter_genes filter_genes(min_count=0, max_count=None, qc_var='n_cells_by_counts', qc=False) Filter genes based on number of a QC metric. Args: min_count ( int ): Minimum number of counts required for a gene to pass filtering. max_count ( int ): Maximum number of counts required for a gene to pass filtering. qc_var ( str ='n_cells_by_counts'): Feature in QC metrics that used to filter genes. qc ( bool = False ): Call calculate_qc_metrics before filtering. method filter_genes_and_cells filter_genes_and_cells( min_counts_per_gene=0, min_counts_per_cell=0, max_counts_per_gene=None, max_counts_per_cell=None, qc_var_gene='n_cells_by_counts', qc_var_cell='n_genes_by_counts', qc=False ) Filter genes based on number of a QC metric. Note: This is an efficient way to perform a regular filtering on genes and cells without repeatedly iterating over chunks. Args: min_counts_per_gene ( int ): Minimum number of counts required for a gene to pass filtering. max_counts_per_gene ( int ): Maximum number of counts required for a gene to pass filtering. qc_var_gene ( str ='n_cells_by_counts'): Feature in QC metrics that used to filter genes. min_counts_per_cell ( int ): Minimum number of counts required for a cell to pass filtering. max_counts_per_cell ( int ): Maximum number of counts required for a cell to pass filtering. qc_var_cell ( str ='n_genes_by_counts'): Feature in QC metrics that used to filter cells. qc ( bool = False ): Call calculate_qc_metrics before filtering. method harmony harmony(sample_col_name, n_init=10, max_iter_harmony=20) Use Harmony to integrate different experiments. Note: This modified harmony function can easily scale up to 15M cells with 50 pcs on GPU (A100 80G). Result after harmony is stored into adata.obsm['X_pca_harmony'] . Args: sample_col_name ( str ): Column of sample ID. n_init ( int = 10 ): Number of times the k-means algorithm is run with different centroid seeds. max_iter_harmony ( int = 20 ): Maximum iteration number of harmony. method highly_variable_genes highly_variable_genes(n_top_genes=4000, method='seurat_v3') Annotate highly variable genes. Note: Only seurat_v3 is implemented. Count data is expected for seurat_v3 . HVGs are set to True in adata.var['highly_variable'] . Args: n_top_genes ( int = 4000 ): Number of highly-variable genes to keep. method ( str = 'seurat_v3' ): Choose the flavor for identifying highly variable genes. method leiden leiden(resolution=0.5, random_state=42) Performs Leiden clustering using rapids-singlecell . Args: resolution ( float = 0.5 ): A parameter value controlling the coarseness of the clustering. (called gamma in the modularity formula). Higher values lead to more clusters. random_state ( int = 42 ): Random seed. method neighbors neighbors(n_neighbors=20, n_pcs=50, use_rep='X_pac_harmony', algorithm='cagra') Compute a neighborhood graph of observations using rapids-singlecell . Args: n_neighbors ( int = 20 ): The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. n_pcs ( int = 50 ): Use this many PCs. use_rep ( str = 'X_pca_harmony' ): Use the indicated representation. algorithm ( str = 'cagra' ): The query algorithm to use. method normalize_log1p normalize_log1p(target_sum=10000.0) Normalize counts per cell then log1p. Note: If save_raw_counts or save_norm_counts is set, write adata_X to disk here automatically. Args: target_sum ( int = 1e4 ): If None, after normalization, each observation (cell) has a total count equal to the median of total counts for observations (cells) before normalization. method normalize_log1p_pca normalize_log1p_pca( target_sum=10000.0, n_components=50, hvg_var='highly_variable' ) An alternative for calling normalize_log1p and pca together. Note: Used when preload_on_cpu is False . method pca pca(n_components=50, hvg_var='highly_variable') Principal component analysis. Computes PCA coordinates, loadings and variance decomposition. Uses the implementation of scikit-learn. Note: Flip the directions according to the largest values in loadings. Results will match up with scanpy perfectly. Calculated PCA matrix is stored in adata.obsm['X_pca'] . Args: n_components ( int = 50 ): Number of principal components to compute. hvg_var ( str = 'highly_variable' ): Use highly variable genes only. method save save(data_name=None) Save adata to disk. Note: Save to ' output_dir / data_name .h5ad'. Args: data_name ( str ): If None , set as data_dir . method savex savex(name, data_name=None) Save adata to disk in chunks. Note: Each chunk will be saved individually in a subfolder under output_dir . Save to ' output_dir / name / data_name _ i .h5ad'. Args: name ( str ): Subfolder name. data_name ( str ): If None , set as data_dir . method to_CPU to_CPU() Move all chunks to CPU. method to_GPU to_GPU() Move all chunks to GPU. method umap umap(random_state=42) Embed the neighborhood graph using rapids-singlecell . Args: random_state ( int = 42 ): Random seed. This file was automatically generated via lazydocs .","title":"scalesc.pp"},{"location":"api-docs/pp/#module-pp","text":"","title":"module pp"},{"location":"api-docs/pp/#global-variables","text":"get_mean_var_major_kernel get_mean_var_minor_kernel find_indices_kernel","title":"Global Variables"},{"location":"api-docs/pp/#class-scalesc","text":"ScaleSC integrated pipeline in a scanpy-like style. It will automatcially load dataset in chunks, see scalesc.util.AnnDataBatchReader for details, and all methods in this class manipulate this chunked data. Args: data_dir ( str ): Data folder of the dataset. max_cell_batch ( int ): Maximum number of cells in a single batch. Default : 100000. preload_on_cpu ( bool ): If load the entire chunked data on CPU. Default: True preload_on_gpu ( bool ): If load the entire chunked data on GPU, preload_on_cpu will be overwritten to True when this sets to True . Default : True . save_raw_counts ( bool ): If save adata_X to disk after QC filtering. Default : False. save_norm_counts ( bool ): If save adata_X data to disk after normalization. Default : False. save_after_each_step ( bool ): If save adata (without .X) to disk after each step. Default : False. output_dir ( str ): Output folder. Default: './results'. gpus ( list ): List of GPU ids, [0] is set if this is None. Default: None.","title":"class ScaleSC"},{"location":"api-docs/pp/#method-__init__","text":"__init__( data_dir, max_cell_batch=100000.0, preload_on_cpu=True, preload_on_gpu=True, save_raw_counts=False, save_norm_counts=False, save_after_each_step=False, output_dir='results', gpus=None )","title":"method __init__"},{"location":"api-docs/pp/#property-adata","text":"AnnData : An AnnData object that used to store all intermediate results without the count matrix. Note: This is always on CPU.","title":"property adata"},{"location":"api-docs/pp/#property-adata_x","text":"AnnData : An AnnData object that used to store all intermediate results including the count matrix. Internally, all chunks should be merged on CPU to avoid high GPU consumption, make sure to invoke to_CPU() before calling this object.","title":"property adata_X"},{"location":"api-docs/pp/#method-calculate_qc_metrics","text":"calculate_qc_metrics() Calculate quality control metrics.","title":"method calculate_qc_metrics"},{"location":"api-docs/pp/#method-clear","text":"clear() Clean the memory","title":"method clear"},{"location":"api-docs/pp/#method-filter_cells","text":"filter_cells(min_count=0, max_count=None, qc_var='n_genes_by_counts', qc=False) Filter genes based on number of a QC metric. Args: min_count ( int ): Minimum number of counts required for a cell to pass filtering. max_count ( int ): Maximum number of counts required for a cell to pass filtering. qc_var ( str ='n_genes_by_counts'): Feature in QC metrics that used to filter cells. qc ( bool = False ): Call calculate_qc_metrics before filtering.","title":"method filter_cells"},{"location":"api-docs/pp/#method-filter_genes","text":"filter_genes(min_count=0, max_count=None, qc_var='n_cells_by_counts', qc=False) Filter genes based on number of a QC metric. Args: min_count ( int ): Minimum number of counts required for a gene to pass filtering. max_count ( int ): Maximum number of counts required for a gene to pass filtering. qc_var ( str ='n_cells_by_counts'): Feature in QC metrics that used to filter genes. qc ( bool = False ): Call calculate_qc_metrics before filtering.","title":"method filter_genes"},{"location":"api-docs/pp/#method-filter_genes_and_cells","text":"filter_genes_and_cells( min_counts_per_gene=0, min_counts_per_cell=0, max_counts_per_gene=None, max_counts_per_cell=None, qc_var_gene='n_cells_by_counts', qc_var_cell='n_genes_by_counts', qc=False ) Filter genes based on number of a QC metric. Note: This is an efficient way to perform a regular filtering on genes and cells without repeatedly iterating over chunks. Args: min_counts_per_gene ( int ): Minimum number of counts required for a gene to pass filtering. max_counts_per_gene ( int ): Maximum number of counts required for a gene to pass filtering. qc_var_gene ( str ='n_cells_by_counts'): Feature in QC metrics that used to filter genes. min_counts_per_cell ( int ): Minimum number of counts required for a cell to pass filtering. max_counts_per_cell ( int ): Maximum number of counts required for a cell to pass filtering. qc_var_cell ( str ='n_genes_by_counts'): Feature in QC metrics that used to filter cells. qc ( bool = False ): Call calculate_qc_metrics before filtering.","title":"method filter_genes_and_cells"},{"location":"api-docs/pp/#method-harmony","text":"harmony(sample_col_name, n_init=10, max_iter_harmony=20) Use Harmony to integrate different experiments. Note: This modified harmony function can easily scale up to 15M cells with 50 pcs on GPU (A100 80G). Result after harmony is stored into adata.obsm['X_pca_harmony'] . Args: sample_col_name ( str ): Column of sample ID. n_init ( int = 10 ): Number of times the k-means algorithm is run with different centroid seeds. max_iter_harmony ( int = 20 ): Maximum iteration number of harmony.","title":"method harmony"},{"location":"api-docs/pp/#method-highly_variable_genes","text":"highly_variable_genes(n_top_genes=4000, method='seurat_v3') Annotate highly variable genes. Note: Only seurat_v3 is implemented. Count data is expected for seurat_v3 . HVGs are set to True in adata.var['highly_variable'] . Args: n_top_genes ( int = 4000 ): Number of highly-variable genes to keep. method ( str = 'seurat_v3' ): Choose the flavor for identifying highly variable genes.","title":"method highly_variable_genes"},{"location":"api-docs/pp/#method-leiden","text":"leiden(resolution=0.5, random_state=42) Performs Leiden clustering using rapids-singlecell . Args: resolution ( float = 0.5 ): A parameter value controlling the coarseness of the clustering. (called gamma in the modularity formula). Higher values lead to more clusters. random_state ( int = 42 ): Random seed.","title":"method leiden"},{"location":"api-docs/pp/#method-neighbors","text":"neighbors(n_neighbors=20, n_pcs=50, use_rep='X_pac_harmony', algorithm='cagra') Compute a neighborhood graph of observations using rapids-singlecell . Args: n_neighbors ( int = 20 ): The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. n_pcs ( int = 50 ): Use this many PCs. use_rep ( str = 'X_pca_harmony' ): Use the indicated representation. algorithm ( str = 'cagra' ): The query algorithm to use.","title":"method neighbors"},{"location":"api-docs/pp/#method-normalize_log1p","text":"normalize_log1p(target_sum=10000.0) Normalize counts per cell then log1p. Note: If save_raw_counts or save_norm_counts is set, write adata_X to disk here automatically. Args: target_sum ( int = 1e4 ): If None, after normalization, each observation (cell) has a total count equal to the median of total counts for observations (cells) before normalization.","title":"method normalize_log1p"},{"location":"api-docs/pp/#method-normalize_log1p_pca","text":"normalize_log1p_pca( target_sum=10000.0, n_components=50, hvg_var='highly_variable' ) An alternative for calling normalize_log1p and pca together. Note: Used when preload_on_cpu is False .","title":"method normalize_log1p_pca"},{"location":"api-docs/pp/#method-pca","text":"pca(n_components=50, hvg_var='highly_variable') Principal component analysis. Computes PCA coordinates, loadings and variance decomposition. Uses the implementation of scikit-learn. Note: Flip the directions according to the largest values in loadings. Results will match up with scanpy perfectly. Calculated PCA matrix is stored in adata.obsm['X_pca'] . Args: n_components ( int = 50 ): Number of principal components to compute. hvg_var ( str = 'highly_variable' ): Use highly variable genes only.","title":"method pca"},{"location":"api-docs/pp/#method-save","text":"save(data_name=None) Save adata to disk. Note: Save to ' output_dir / data_name .h5ad'. Args: data_name ( str ): If None , set as data_dir .","title":"method save"},{"location":"api-docs/pp/#method-savex","text":"savex(name, data_name=None) Save adata to disk in chunks. Note: Each chunk will be saved individually in a subfolder under output_dir . Save to ' output_dir / name / data_name _ i .h5ad'. Args: name ( str ): Subfolder name. data_name ( str ): If None , set as data_dir .","title":"method savex"},{"location":"api-docs/pp/#method-to_cpu","text":"to_CPU() Move all chunks to CPU.","title":"method to_CPU"},{"location":"api-docs/pp/#method-to_gpu","text":"to_GPU() Move all chunks to GPU.","title":"method to_GPU"},{"location":"api-docs/pp/#method-umap","text":"umap(random_state=42) Embed the neighborhood graph using rapids-singlecell . Args: random_state ( int = 42 ): Random seed. This file was automatically generated via lazydocs .","title":"method umap"},{"location":"api-docs/trim_merge_marker/","text":"module trim_merge_marker Global Variables TYPE_CHECKING get_mean_var_major_kernel get_mean_var_minor_kernel find_indices_kernel function timer timer(func) function wrapper wrapper(*args, **kwargs) function wrapper wrapper(*args, **kwargs) function wrapper wrapper(*args, **kwargs) function wrapper wrapper(*args, **kwargs) function wrapper wrapper(*args, **kwargs) function wrapper wrapper(*args, **kwargs) function wrapper wrapper(*args, **kwargs) function X_to_GPU X_to_GPU(X) Transfers matrices and arrays to the GPU. Args: X : Matrix or array to transfer to the GPU. function marker_filter_sort marker_filter_sort(markers, cluster, df_sp, df_frac) function find_markers find_markers(adata, subctype_col) function stds stds(x, axis=None) Variance of sparse matrix a var = mean(a 2) - mean(a) 2 Standard deviation of sparse matrix a std = sqrt(var(a)) function find_cluster_pairs_to_merge find_cluster_pairs_to_merge(adata, x, colname, cluster, markers) function adata_cluster_merge adata_cluster_merge(adata, subctype_col) Need a description. function specificity_score specificity_score(adata=None, ctype_col: str = None, glist: list = None) function fraction_cells fraction_cells(adata=None, ctype_col: str = None, glist: list = None) Given adata.X (n cells * m genes), ctype_col (a column name in adata.obs that stores the cell type annotation), and a glist (for example, [gene1, gene2, ..., genek]) The definiation of Fraction of expression := # cells>0 / # total cells. Assume in total c different cell types for each cell type, subset the adata, and then calculate the fraction of expression of each gene return the fraction dataframe, k rows, c columns. function myNSForest myNSForest( adata, cluster_header, cluster_list=None, medians_header=None, n_trees=100, n_jobs=-1, beta=0.5, n_top_genes=15, n_binary_genes=10, n_genes_eval=6, output_folder='.', save_results=False ) class UF method __init__ __init__(n) method current_kids_dict current_kids_dict() method final final() method find find(x) method union union(x, y) class data2UF method __init__ __init__(celltypes: list, merge_pairs: list[tuple]) method union_pairs union_pairs() \u2192 int This file was automatically generated via lazydocs .","title":"scalesc.trim_merge_marker"},{"location":"api-docs/trim_merge_marker/#module-trim_merge_marker","text":"","title":"module trim_merge_marker"},{"location":"api-docs/trim_merge_marker/#global-variables","text":"TYPE_CHECKING get_mean_var_major_kernel get_mean_var_minor_kernel find_indices_kernel","title":"Global Variables"},{"location":"api-docs/trim_merge_marker/#function-timer","text":"timer(func)","title":"function timer"},{"location":"api-docs/trim_merge_marker/#function-wrapper","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-wrapper_1","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-wrapper_2","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-wrapper_3","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-wrapper_4","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-wrapper_5","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-wrapper_6","text":"wrapper(*args, **kwargs)","title":"function wrapper"},{"location":"api-docs/trim_merge_marker/#function-x_to_gpu","text":"X_to_GPU(X) Transfers matrices and arrays to the GPU. Args: X : Matrix or array to transfer to the GPU.","title":"function X_to_GPU"},{"location":"api-docs/trim_merge_marker/#function-marker_filter_sort","text":"marker_filter_sort(markers, cluster, df_sp, df_frac)","title":"function marker_filter_sort"},{"location":"api-docs/trim_merge_marker/#function-find_markers","text":"find_markers(adata, subctype_col)","title":"function find_markers"},{"location":"api-docs/trim_merge_marker/#function-stds","text":"stds(x, axis=None) Variance of sparse matrix a var = mean(a 2) - mean(a) 2 Standard deviation of sparse matrix a std = sqrt(var(a))","title":"function stds"},{"location":"api-docs/trim_merge_marker/#function-find_cluster_pairs_to_merge","text":"find_cluster_pairs_to_merge(adata, x, colname, cluster, markers)","title":"function find_cluster_pairs_to_merge"},{"location":"api-docs/trim_merge_marker/#function-adata_cluster_merge","text":"adata_cluster_merge(adata, subctype_col) Need a description.","title":"function adata_cluster_merge"},{"location":"api-docs/trim_merge_marker/#function-specificity_score","text":"specificity_score(adata=None, ctype_col: str = None, glist: list = None)","title":"function specificity_score"},{"location":"api-docs/trim_merge_marker/#function-fraction_cells","text":"fraction_cells(adata=None, ctype_col: str = None, glist: list = None) Given adata.X (n cells * m genes), ctype_col (a column name in adata.obs that stores the cell type annotation), and a glist (for example, [gene1, gene2, ..., genek]) The definiation of Fraction of expression := # cells>0 / # total cells. Assume in total c different cell types for each cell type, subset the adata, and then calculate the fraction of expression of each gene return the fraction dataframe, k rows, c columns.","title":"function fraction_cells"},{"location":"api-docs/trim_merge_marker/#function-mynsforest","text":"myNSForest( adata, cluster_header, cluster_list=None, medians_header=None, n_trees=100, n_jobs=-1, beta=0.5, n_top_genes=15, n_binary_genes=10, n_genes_eval=6, output_folder='.', save_results=False )","title":"function myNSForest"},{"location":"api-docs/trim_merge_marker/#class-uf","text":"","title":"class UF"},{"location":"api-docs/trim_merge_marker/#method-__init__","text":"__init__(n)","title":"method __init__"},{"location":"api-docs/trim_merge_marker/#method-current_kids_dict","text":"current_kids_dict()","title":"method current_kids_dict"},{"location":"api-docs/trim_merge_marker/#method-final","text":"final()","title":"method final"},{"location":"api-docs/trim_merge_marker/#method-find","text":"find(x)","title":"method find"},{"location":"api-docs/trim_merge_marker/#method-union","text":"union(x, y)","title":"method union"},{"location":"api-docs/trim_merge_marker/#class-data2uf","text":"","title":"class data2UF"},{"location":"api-docs/trim_merge_marker/#method-__init___1","text":"__init__(celltypes: list, merge_pairs: list[tuple])","title":"method __init__"},{"location":"api-docs/trim_merge_marker/#method-union_pairs","text":"union_pairs() \u2192 int This file was automatically generated via lazydocs .","title":"method union_pairs"},{"location":"api-docs/util/","text":"module util Global Variables TYPE_CHECKING GPU_MEMORY_LIMIT GPU_MEMORY_USAGE function filter_cells filter_cells(adata, qc_var, min_count, max_count) Cell filtering according to min and max gene counts. Note: filter_cells in rsc doesn't support filter out cells by min and max counts at the same time. a modification is made here for dealing with both together. function svd_flip svd_flip(pcs) Flip the signs of loading according to sign(max(abs(loadings))). Note: this function is used to match up scanpy's results of PCA. Args: pcs (:obj: np.ndarray | cp.ndarray ): PC loadings. Returns: pcs_adjusted (:obj: np.ndarray | cp.ndarray ): Flipped loadings. function check_dtype check_dtype(adata) Convert dtype to float32 or float64 . Note: rapids-singlecell doesn't support sparse matrix under float16 . function gc gc() Release CPU and GPU RAM function get_mean_var get_mean_var(X, axis=0) Calculating mean and variance of a given matrix based on customized kernels. Note: No such methods implemented yet for csr_matrix . function check_nonnegative_integers check_nonnegative_integers(X) Check if X is a nonnegative integer matrix. Note: Check values of data to ensure it is count data. function harmony harmony( adata, key, basis='X_pca', adjusted_basis='X_pca_harmony', init_seeds=None, n_init=1, dtype=<class 'numpy.float32'>, max_iter_harmony=10, random_state=0, **kwargs ) Harmony GPU version. function correct_leiden correct_leiden(adata) function find_indices find_indices(A, indptr, out_rows) function csr_indptr_to_coo_rows csr_indptr_to_coo_rows(nnz, Bp) function csr_row_index csr_row_index(Ax, Aj, Ap, rows) Populate indices and data arrays from the given row index. Args: Ax ( cupy.ndarray ): data array from input sparse matrix Aj ( cupy.ndarray ): indices array from input sparse matrix Ap ( cupy.ndarray ): indptr array from input sparse matrix rows ( cupy.ndarray ): index array of rows to populate Returns: Bx ( cupy.ndarray ): data array of output sparse matrix Bj ( cupy.ndarray ): indices array of output sparse matrix Bp ( cupy.ndarray ): indptr array for output sparse matrix function csr_col_index csr_col_index(Ax, Aj, Ai, cols, shape) function write_to_disk write_to_disk(adata, output_dir, data_name, batch_name=None) class AnnDataBatchReader Chunked dataloader for extremely large single-cell dataset. Return a data chunk each time for further processing. method __init__ __init__( data_dir, preload_on_cpu=True, preload_on_gpu=False, gpus=None, max_cell_batch=100000, max_gpu_memory_usage=48.0, return_anndata=True ) property shape method batch_to_CPU batch_to_CPU() method batch_to_GPU batch_to_GPU() method batchify batchify(axis='cell') Return a data generator if preload_on_cpu is set as True . method clear clear() method get_merged_adata_with_X get_merged_adata_with_X() method gpu_wrapper gpu_wrapper(generator) method read read(fname) method set_cells_filter set_cells_filter(filter, update=True) Update cells filter and applied on data chunks if update set to True , otherwise, update filter only. method set_genes_filter set_genes_filter(filter, update=True) Update genes filter and applied on data chunks if update set to True, otherwise, update filter only. Note: Genes filter can be set sequentially, a new filter should be always compatible with the previous filtered data. method update_by_cells_filter update_by_cells_filter(filter) method update_by_genes_filter update_by_genes_filter(filter) This file was automatically generated via lazydocs .","title":"scalesc.util"},{"location":"api-docs/util/#module-util","text":"","title":"module util"},{"location":"api-docs/util/#global-variables","text":"TYPE_CHECKING GPU_MEMORY_LIMIT GPU_MEMORY_USAGE","title":"Global Variables"},{"location":"api-docs/util/#function-filter_cells","text":"filter_cells(adata, qc_var, min_count, max_count) Cell filtering according to min and max gene counts. Note: filter_cells in rsc doesn't support filter out cells by min and max counts at the same time. a modification is made here for dealing with both together.","title":"function filter_cells"},{"location":"api-docs/util/#function-svd_flip","text":"svd_flip(pcs) Flip the signs of loading according to sign(max(abs(loadings))). Note: this function is used to match up scanpy's results of PCA. Args: pcs (:obj: np.ndarray | cp.ndarray ): PC loadings. Returns: pcs_adjusted (:obj: np.ndarray | cp.ndarray ): Flipped loadings.","title":"function svd_flip"},{"location":"api-docs/util/#function-check_dtype","text":"check_dtype(adata) Convert dtype to float32 or float64 . Note: rapids-singlecell doesn't support sparse matrix under float16 .","title":"function check_dtype"},{"location":"api-docs/util/#function-gc","text":"gc() Release CPU and GPU RAM","title":"function gc"},{"location":"api-docs/util/#function-get_mean_var","text":"get_mean_var(X, axis=0) Calculating mean and variance of a given matrix based on customized kernels. Note: No such methods implemented yet for csr_matrix .","title":"function get_mean_var"},{"location":"api-docs/util/#function-check_nonnegative_integers","text":"check_nonnegative_integers(X) Check if X is a nonnegative integer matrix. Note: Check values of data to ensure it is count data.","title":"function check_nonnegative_integers"},{"location":"api-docs/util/#function-harmony","text":"harmony( adata, key, basis='X_pca', adjusted_basis='X_pca_harmony', init_seeds=None, n_init=1, dtype=<class 'numpy.float32'>, max_iter_harmony=10, random_state=0, **kwargs ) Harmony GPU version.","title":"function harmony"},{"location":"api-docs/util/#function-correct_leiden","text":"correct_leiden(adata)","title":"function correct_leiden"},{"location":"api-docs/util/#function-find_indices","text":"find_indices(A, indptr, out_rows)","title":"function find_indices"},{"location":"api-docs/util/#function-csr_indptr_to_coo_rows","text":"csr_indptr_to_coo_rows(nnz, Bp)","title":"function csr_indptr_to_coo_rows"},{"location":"api-docs/util/#function-csr_row_index","text":"csr_row_index(Ax, Aj, Ap, rows) Populate indices and data arrays from the given row index. Args: Ax ( cupy.ndarray ): data array from input sparse matrix Aj ( cupy.ndarray ): indices array from input sparse matrix Ap ( cupy.ndarray ): indptr array from input sparse matrix rows ( cupy.ndarray ): index array of rows to populate Returns: Bx ( cupy.ndarray ): data array of output sparse matrix Bj ( cupy.ndarray ): indices array of output sparse matrix Bp ( cupy.ndarray ): indptr array for output sparse matrix","title":"function csr_row_index"},{"location":"api-docs/util/#function-csr_col_index","text":"csr_col_index(Ax, Aj, Ai, cols, shape)","title":"function csr_col_index"},{"location":"api-docs/util/#function-write_to_disk","text":"write_to_disk(adata, output_dir, data_name, batch_name=None)","title":"function write_to_disk"},{"location":"api-docs/util/#class-anndatabatchreader","text":"Chunked dataloader for extremely large single-cell dataset. Return a data chunk each time for further processing.","title":"class AnnDataBatchReader"},{"location":"api-docs/util/#method-__init__","text":"__init__( data_dir, preload_on_cpu=True, preload_on_gpu=False, gpus=None, max_cell_batch=100000, max_gpu_memory_usage=48.0, return_anndata=True )","title":"method __init__"},{"location":"api-docs/util/#property-shape","text":"","title":"property shape"},{"location":"api-docs/util/#method-batch_to_cpu","text":"batch_to_CPU()","title":"method batch_to_CPU"},{"location":"api-docs/util/#method-batch_to_gpu","text":"batch_to_GPU()","title":"method batch_to_GPU"},{"location":"api-docs/util/#method-batchify","text":"batchify(axis='cell') Return a data generator if preload_on_cpu is set as True .","title":"method batchify"},{"location":"api-docs/util/#method-clear","text":"clear()","title":"method clear"},{"location":"api-docs/util/#method-get_merged_adata_with_x","text":"get_merged_adata_with_X()","title":"method get_merged_adata_with_X"},{"location":"api-docs/util/#method-gpu_wrapper","text":"gpu_wrapper(generator)","title":"method gpu_wrapper"},{"location":"api-docs/util/#method-read","text":"read(fname)","title":"method read"},{"location":"api-docs/util/#method-set_cells_filter","text":"set_cells_filter(filter, update=True) Update cells filter and applied on data chunks if update set to True , otherwise, update filter only.","title":"method set_cells_filter"},{"location":"api-docs/util/#method-set_genes_filter","text":"set_genes_filter(filter, update=True) Update genes filter and applied on data chunks if update set to True, otherwise, update filter only. Note: Genes filter can be set sequentially, a new filter should be always compatible with the previous filtered data.","title":"method set_genes_filter"},{"location":"api-docs/util/#method-update_by_cells_filter","text":"update_by_cells_filter(filter)","title":"method update_by_cells_filter"},{"location":"api-docs/util/#method-update_by_genes_filter","text":"update_by_genes_filter(filter) This file was automatically generated via lazydocs .","title":"method update_by_genes_filter"}]}